"""ç”Ÿæˆé€±å ± Command

æ•´åˆå„ BC æ•¸æ“šï¼Œç”Ÿæˆé€±åº¦è¦†ç›¤ä¸¦å¯é¸ç™¼é€ Email
"""

from datetime import datetime, timedelta
from injector import inject
import logging
import numpy as np
import yfinance as yf
from textwrap import dedent

from libs.monitoring.src.ports.notification_gateway_port import (
    NotificationGatewayPort,
)
from libs.reviewing.src.ports.portfolio_provider_port import (
    PortfolioProviderPort,
)
from libs.reviewing.src.domain.services.dsr_calculator import (
    calculate_deflated_sharpe_ratio,
)
from libs.reviewing.src.domain.services.cvar_calculator import assess_tail_risk
from libs.reviewing.src.domain.services.fdr_controller import control_fdr
from libs.reporting.src.ports.generate_weekly_report_port import (
    GenerateWeeklyReportPort,
)
from libs.shared.src.dtos.reporting.report_result_dto import ReportResultDTO
from libs.shared.src.dtos.reporting.performance_dto import PerformanceDTO
from libs.shared.src.dtos.reporting.skill_metrics_dto import SkillMetricsDTO
from libs.shared.src.dtos.reporting.crowding_metrics_dto import CrowdingMetricsDTO
from libs.shared.src.dtos.reporting.decision_quality_dto import DecisionQualityDTO
from libs.shared.src.dtos.reporting.thesis_validation_dto import ThesisValidationDTO
from libs.shared.src.dtos.reporting.strategy_health_dto import StrategyHealthDTO


class GenerateWeeklyReportCommand(GenerateWeeklyReportPort):
    """ç”Ÿæˆé€±å ±

    æ•´åˆï¼š
    - ç¸¾æ•ˆåˆ†æ (performance_reviewer)
    - æŠ€èƒ½åˆ¤å®š (performance_reviewer)
    - ç­–ç•¥æ“æ“ åº¦ (performance_reviewer)
    - AI æ•˜äº‹ (narration)
    """

    @inject
    def __init__(
        self,
        notification_gateway: NotificationGatewayPort,
        portfolio_provider: PortfolioProviderPort,
    ) -> None:
        self._logger = logging.getLogger(self.__class__.__name__)
        self._notification_gateway = notification_gateway
        self._portfolio_provider = portfolio_provider

    def execute(self, simulate: bool = False) -> ReportResultDTO:
        """åŸ·è¡Œç”Ÿæˆé€±å ±"""

        today = datetime.now()
        period = today.strftime("%Y-W%W")
        self._logger.info(f"é–‹å§‹ç”Ÿæˆé€±å ±: {period}")

        # 1. å–å¾—ç¸¾æ•ˆæ•¸æ“š
        self._logger.info("æ­¥é©Ÿ 1/6: å–å¾—ç¸¾æ•ˆæ•¸æ“š...")
        performance = self._get_performance()
        self._logger.info(f"ç¸¾æ•ˆæ•¸æ“šå®Œæˆ: MTD {performance['mtd_return']:.1%}")

        # 2. å–å¾—æŠ€èƒ½åˆ¤å®š
        self._logger.info("æ­¥é©Ÿ 2/6: å–å¾—æŠ€èƒ½åˆ¤å®š...")
        skill = self._get_skill_metrics()
        self._logger.info(f"æŠ€èƒ½åˆ¤å®šå®Œæˆ: {skill['verdict']}")

        # 3. å–å¾—ç­–ç•¥æ“æ“ åº¦
        self._logger.info("æ­¥é©Ÿ 3/6: å–å¾—ç­–ç•¥æ“æ“ åº¦...")
        crowding = self._get_crowding_metrics()

        # 4. å–å¾—æ±ºç­–å“è³ª
        self._logger.info("æ­¥é©Ÿ 4/6: å–å¾—æ±ºç­–å“è³ª...")
        decision_quality = self._get_decision_quality()

        # 5. å–å¾—è«–é»é©—è­‰
        self._logger.info("æ­¥é©Ÿ 5/6: å–å¾—è«–é»é©—è­‰...")
        thesis_validation = self._get_thesis_validation()

        # 6. å–å¾—ç­–ç•¥å¥åº·åº¦ (DSR/CVaR/CPCV)
        self._logger.info("æ­¥é©Ÿ 6/6: å–å¾—ç­–ç•¥å¥åº·åº¦...")
        strategy_health = self._get_strategy_health()
        self._logger.info(f"ç­–ç•¥å¥åº·åº¦å®Œæˆ: DSR={strategy_health['dsr']:.2f}")

        # ç”Ÿæˆ Markdown å ±å‘Š (å«åˆ¤æº–å®šç¾©)
        self._logger.info("ç”Ÿæˆ Markdown å ±å‘Š...")
        report_markdown = self._generate_report(
            period=period,
            performance=performance,
            skill=skill,
            crowding=crowding,
            decision_quality=decision_quality,
            thesis_validation=thesis_validation,
            strategy_health=strategy_health,
        )
        self._logger.info("Markdown å ±å‘Šå®Œæˆ")

        result = {
            "period": period,
            "performance": performance,
            "skill": skill,
            "crowding": crowding,
            "decision_quality": decision_quality,
            "thesis_validation": thesis_validation,
            "strategy_health": strategy_health,
            "report_markdown": report_markdown,
            "email_sent": False,
        }

        self._logger.info("ç™¼é€ Email...")
        result["email_sent"] = self._send_email(report_markdown, period)
        self._logger.info(f"Email ç™¼é€: {'æˆåŠŸ' if result['email_sent'] else 'å¤±æ•—'}")

        self._logger.info("é€±å ±ç”Ÿæˆå®Œæˆ")
        return result

    def _get_performance(self) -> PerformanceDTO:
        """å–å¾—ç¸¾æ•ˆæ•¸æ“š (å¾ Shioaji å–å¾—çœŸå¯¦äº¤æ˜“è³‡æ–™)"""
        try:
            adapter = self._portfolio_provider

            if not adapter.connect():
                return self._default_performance("âš ï¸ ç„¡æ³•é€£ç·š Shioaji")

            # 1. å–å¾—ç•¶å‰æŒå€‰ (æœªå¯¦ç¾æç›Š)
            positions = adapter.get_positions()
            unrealized_pnl = (
                sum(pos.get("pnl", 0) for pos in positions) if positions else 0
            )

            # 2. å–å¾—æœ¬é€±äº¤æ˜“è¨˜éŒ„ (WTD)
            today = datetime.now()
            week_start = today - timedelta(days=today.weekday())  # æœ¬é€±ä¸€
            wtd_trades = adapter.get_profit_loss_history(
                begin_date=week_start.strftime("%Y-%m-%d"),
                end_date=today.strftime("%Y-%m-%d"),
            )

            # 3. å–å¾—ä»Šå¹´äº¤æ˜“è¨˜éŒ„ (YTD)
            year_start = datetime(today.year, 1, 1)
            ytd_trades = adapter.get_profit_loss_history(
                begin_date=year_start.strftime("%Y-%m-%d"),
                end_date=today.strftime("%Y-%m-%d"),
            )

            adapter.disconnect()

            # è¨ˆç®— WTD å ±é…¬
            wtd_pnl = sum(t.get("pnl", 0) for t in wtd_trades)
            wtd_cost = sum(t.get("cost", 0) for t in wtd_trades)
            wtd_return = wtd_pnl / wtd_cost if wtd_cost > 0 else 0

            # è¨ˆç®— YTD å ±é…¬
            ytd_pnl = sum(t.get("pnl", 0) for t in ytd_trades)
            ytd_cost = sum(t.get("cost", 0) for t in ytd_trades)
            ytd_return = ytd_pnl / ytd_cost if ytd_cost > 0 else 0

            # è¨ˆç®—å‹ç‡èˆ‡ç›ˆè™§æ¯” (ä½¿ç”¨ YTD è³‡æ–™)
            wins = [t for t in ytd_trades if t.get("pnl", 0) > 0]
            losses = [t for t in ytd_trades if t.get("pnl", 0) < 0]
            total_trades = len(wins) + len(losses)

            win_rate = len(wins) / total_trades if total_trades > 0 else 0
            avg_win = sum(t.get("pnl", 0) for t in wins) / len(wins) if wins else 0
            avg_loss = (
                abs(sum(t.get("pnl", 0) for t in losses) / len(losses)) if losses else 0
            )
            profit_factor = avg_win / avg_loss if avg_loss > 0 else 0

            # è¨ˆç®—å¤æ™®æ¯”ç‡ (ç°¡åŒ–ç‰ˆï¼šä½¿ç”¨æ¯ç­†äº¤æ˜“å ±é…¬ç‡)
            if len(ytd_trades) >= 5:
                returns = [
                    t.get("pnl", 0) / t.get("cost", 1)
                    for t in ytd_trades
                    if t.get("cost", 0) > 0
                ]
                if returns:
                    mean_ret = np.mean(returns)
                    std_ret = np.std(returns)
                    # å¹´åŒ–å¤æ™® (å‡è¨­æ¯æœˆç´„ 10 ç­†äº¤æ˜“)
                    sharpe = (mean_ret / std_ret) * np.sqrt(120) if std_ret > 0 else 0
                else:
                    sharpe = 0
            else:
                sharpe = 0

            # è¨ˆç®—æœ€å¤§å›æ’¤ (ä½¿ç”¨ç´¯è¨ˆæç›Š)
            if ytd_trades:
                cumulative = []
                running = 0
                for t in ytd_trades:
                    running += t.get("pnl", 0)
                    cumulative.append(running)

                peak = cumulative[0]
                max_dd = 0
                for val in cumulative:
                    if val > peak:
                        peak = val
                    dd = (peak - val) / peak if peak > 0 else 0
                    if dd > max_dd:
                        max_dd = dd
            else:
                max_dd = 0

            note = f"âœ… è³‡æ–™ä¾†æº: Shioaji ({len(ytd_trades)} ç­† YTD äº¤æ˜“)"
            if not ytd_trades:
                note = "âš ï¸ ä»Šå¹´å°šç„¡å·²å¯¦ç¾äº¤æ˜“è¨˜éŒ„"

            return {
                "mtd_return": round(wtd_return, 4),
                "ytd_return": round(ytd_return, 4),
                "sharpe_ratio": round(sharpe, 2),
                "max_drawdown": round(max_dd, 4),
                "win_rate": round(win_rate, 4),
                "profit_factor": round(profit_factor, 2),
                "avg_win": round(avg_win, 2),
                "avg_loss": round(avg_loss, 2),
                "note": note,
                "total_trades": total_trades,
                "unrealized_pnl": round(unrealized_pnl, 2),
            }
        except Exception as e:
            self._logger.warning(f"ç¸¾æ•ˆç²å–å¤±æ•—: {e}")
            return self._default_performance(f"âš ï¸ è³‡æ–™ç²å–å¤±æ•—: {e}")

    def _default_performance(self, note: str) -> PerformanceDTO:
        """é è¨­ç¸¾æ•ˆè³‡æ–™ï¼ˆè³‡æ–™ä¸è¶³æ™‚ï¼‰"""
        return {
            "mtd_return": 0.0,
            "ytd_return": 0.0,
            "sharpe_ratio": 0.0,
            "max_drawdown": 0.0,
            "win_rate": 0.0,
            "profit_factor": 0.0,
            "avg_win": 0.0,
            "avg_loss": 0.0,
            "note": note,
            "total_trades": 0,
            "unrealized_pnl": 0.0,
        }

    def _get_skill_metrics(self) -> SkillMetricsDTO:
        """å–å¾—æŠ€èƒ½åˆ¤å®šï¼ˆä½¿ç”¨çœŸå¯¦äº¤æ˜“è³‡æ–™è¨ˆç®— DSR/PSRï¼‰"""
        try:
            adapter = self._portfolio_provider

            if not adapter.connect():
                return self._default_skill_metrics("âš ï¸ ç„¡æ³•é€£ç·š")

            # å–å¾—éå»ä¸€å¹´çš„äº¤æ˜“ç´€éŒ„
            today = datetime.now()
            year_ago = today - timedelta(days=365)
            trades = adapter.get_profit_loss_history(
                begin_date=year_ago.strftime("%Y-%m-%d"),
                end_date=today.strftime("%Y-%m-%d"),
            )
            adapter.disconnect()

            if len(trades) < 10:
                return self._default_skill_metrics(
                    f"éœ€ç´¯ç©è‡³å°‘ 10 ç­†äº¤æ˜“ (ç›®å‰ {len(trades)} ç­†)"
                )

            # è¨ˆç®—æ¯ç­†äº¤æ˜“å ±é…¬ç‡
            returns = [
                t.get("pnl", 0) / t.get("cost", 1)
                for t in trades
                if t.get("cost", 0) > 0
            ]

            if not returns:
                return self._default_skill_metrics("âš ï¸ ç„¡æœ‰æ•ˆäº¤æ˜“è³‡æ–™")

            # è¨ˆç®—å¤æ™®æ¯”ç‡
            mean_ret = np.mean(returns)
            std_ret = np.std(returns)
            sharpe = (mean_ret / std_ret) * np.sqrt(120) if std_ret > 0 else 0

            # è¨ˆç®— DSR (Deflated Sharpe Ratio)
            dsr = calculate_deflated_sharpe_ratio(
                sr=sharpe,
                n_trials=5,  # å‡è¨­æ¸¬è©¦é 5 å€‹ç­–ç•¥è®Šé«”
                n_observations=len(returns),
                sr_std=1.0,
            )

            # è¨ˆç®— PSR (Probabilistic Sharpe Ratio)
            # PSR = Î¦((SR - SR_benchmark) * âˆš(n-1) / âˆš(1 - skew*SR + (kurtosis-1)/4 * SRÂ²))
            from scipy import stats

            n = len(returns)
            skew = stats.skew(returns) if n > 2 else 0
            kurtosis = stats.kurtosis(returns) if n > 3 else 3
            sr_benchmark = 0  # åŸºæº–å¤æ™® = 0

            denominator = np.sqrt(1 - skew * sharpe + (kurtosis - 1) / 4 * sharpe**2)
            if denominator > 0 and n > 1:
                z_score = (sharpe - sr_benchmark) * np.sqrt(n - 1) / denominator
                psr = stats.norm.cdf(z_score) * 100  # è½‰æ›ç‚ºç™¾åˆ†æ¯”
            else:
                psr = 50.0

            # åˆ¤å®šçµæœ (methodology.md: DSR â‰¥ 0.95 æœ‰æ•ˆï¼Œ0.80-0.95 ç°è‰²åœ°å¸¶)
            if dsr >= 0.95:
                verdict = "âœ… æœ‰æ•ˆç­–ç•¥"
                confidence = "é«˜"
            elif dsr >= 0.80:
                verdict = "ğŸŸ¡ ç°è‰²åœ°å¸¶ (å¾…é€²ä¸€æ­¥é©—è­‰)"
                confidence = "ä¸­"
            else:
                verdict = "âš ï¸ å½é™½æ€§é¢¨éšª"
                confidence = "ä½"

            return {
                "dsr": round(dsr, 2),
                "psr": round(psr, 1),
                "verdict": verdict,
                "confidence": confidence,
                "note": f"âœ… è³‡æ–™ä¾†æº: {len(trades)} ç­†äº¤æ˜“",
            }
        except Exception as e:
            self._logger.warning(f"æŠ€èƒ½åˆ¤å®šå¤±æ•—: {e}")
            return self._default_skill_metrics(f"âš ï¸ è¨ˆç®—å¤±æ•—: {e}")

    def _default_skill_metrics(self, note: str) -> SkillMetricsDTO:
        """é è¨­æŠ€èƒ½åˆ¤å®šï¼ˆè³‡æ–™ä¸è¶³æ™‚ï¼‰"""
        return {
            "dsr": 0.0,
            "psr": 0.0,
            "verdict": "N/A (è³‡æ–™ä¸è¶³)",
            "confidence": "ç„¡æ³•åˆ¤å®š",
            "note": note,
        }

    def _get_crowding_metrics(self) -> CrowdingMetricsDTO:
        """å–å¾—ç­–ç•¥æ“æ“ åº¦ï¼ˆä½¿ç”¨çœŸå¯¦æŒå€‰è³‡æ–™ï¼‰

        ä½¿ç”¨ reviewing/domain/services/crowding_detector.py è¨ˆç®—ï¼š
        1. calculate_pairwise_correlation() - æˆå°ç›¸é—œæ€§
        2. estimate_alpha_half_life() - Alpha åŠè¡°æœŸ
        3. calculate_days_to_cover() - æµå‹•æ€§å¤©æ•¸
        4. assess_crowding() - ç¶œåˆè©•ä¼°
        """
        try:
            from libs.reviewing.src.domain.services.crowding_detector import (
                calculate_pairwise_correlation,
                calculate_days_to_cover,
                estimate_alpha_half_life,
                assess_crowding,
            )

            # 1. å¾ Shioaji å–å¾—çœŸå¯¦æŒå€‰
            adapter = self._portfolio_provider
            if not adapter.connect():
                return self._default_crowding_metrics()

            positions = adapter.get_positions()
            adapter.disconnect()

            if not positions or len(positions) < 2:
                return self._default_crowding_metrics()

            # 2. å–å¾—æŒå€‰è‚¡ç¥¨çš„æ­·å²åƒ¹æ ¼
            symbols = [p["symbol"] + ".TW" for p in positions]
            hist = yf.download(
                symbols,
                period="6mo",
                progress=False,
                auto_adjust=True,
            )

            if hist.empty:
                return self._default_crowding_metrics()

            # 3. è¨ˆç®—å ±é…¬çŸ©é™£
            if len(symbols) == 1:
                # å–®ä¸€æŒå€‰ç„¡æ³•è¨ˆç®—æˆå°ç›¸é—œæ€§
                return self._default_crowding_metrics()

            closes = hist["Close"]
            if closes.isna().all().all():
                return self._default_crowding_metrics()

            # ç§»é™¤å…¨éƒ¨æ˜¯ NaN çš„æ¬„ä½ï¼Œä¸¦å¡«è£œç¼ºå¤±å€¼
            closes = closes.dropna(axis=1, how="all").ffill().bfill()
            if closes.shape[1] < 2:
                return self._default_crowding_metrics()

            returns = np.log(closes).diff().dropna()
            if len(returns) < 30:
                return self._default_crowding_metrics()

            returns_matrix = returns.values

            # 4. è¨ˆç®—æˆå°ç›¸é—œæ€§
            pairwise_corr = calculate_pairwise_correlation(returns_matrix)

            # 5. ä¼°ç®— Alpha åŠè¡°æœŸ (ä½¿ç”¨çµ„åˆå ±é…¬å‡å€¼)
            portfolio_returns = returns.mean(axis=1).values
            alpha_returns = portfolio_returns - np.mean(portfolio_returns)
            half_life = estimate_alpha_half_life(alpha_returns)
            half_life_weeks = half_life / 5.0  # è½‰æ›ç‚ºé€±

            # 6. è¨ˆç®—å¹³å€‰å¤©æ•¸ (ä½¿ç”¨çœŸå¯¦æŒå€‰åƒ¹å€¼)
            position_value = sum(
                p.get("current_price", 0) * p.get("quantity", 0) for p in positions
            )

            # è¨ˆç®—å¹³å‡æ—¥æˆäº¤é‡
            if "Volume" in hist.columns:
                volumes = hist["Volume"]
                avg_volume = volumes.mean().sum() if not volumes.empty else 0
                avg_daily_volume = avg_volume * float(closes.iloc[-1].mean())
            else:
                avg_daily_volume = position_value * 0.1  # é è¨­å‡è¨­æ—¥å‘¨è½‰ç‡ 10%

            days_to_cover = calculate_days_to_cover(
                position_value=position_value,
                avg_daily_volume=avg_daily_volume if avg_daily_volume > 0 else 1,
            )

            # 7. ç¶œåˆè©•ä¼°
            crowding_assessment = assess_crowding(
                pairwise_corr=pairwise_corr,
                days_to_cover=days_to_cover,
                dsr=1.0,  # DSR åœ¨ç­–ç•¥å¥åº·åº¦å€å¡Šè¨ˆç®—
                alpha_half_life=half_life,
            )

            return {
                "pairwise_correlation": round(pairwise_corr, 2),
                "days_to_cover": round(days_to_cover, 1),
                "alpha_half_life": round(half_life_weeks, 1),
                "status": crowding_assessment["status"],
                "recommendation": crowding_assessment["action"],
                "note": f"âœ… è³‡æ–™ä¾†æº: {len(positions)} æª”æŒå€‰",
            }
        except Exception as e:
            self._logger.warning(f"æ“æ“ åº¦è¨ˆç®—å¤±æ•—: {e}")
            return self._default_crowding_metrics()

    def _default_crowding_metrics(self) -> CrowdingMetricsDTO:
        """é è¨­æ“æ“ åº¦æŒ‡æ¨™ï¼ˆè³‡æ–™ä¸è¶³æ™‚ï¼‰"""
        return {
            "pairwise_correlation": 0.0,
            "days_to_cover": 0.0,
            "alpha_half_life": 0.0,
            "status": "N/A",
            "recommendation": "å°šç„¡è¶³å¤ æ•¸æ“šè©•ä¼°æ“æ“ åº¦",
            "note": "âš ï¸ éœ€è‡³å°‘ 2 æª”æŒå€‰æ‰èƒ½è¨ˆç®—",
        }

    def _get_decision_quality(self) -> DecisionQualityDTO:
        """å–å¾—æ±ºç­–å“è³ªï¼ˆå¾ Shioaji äº¤æ˜“ç´€éŒ„åˆ†æï¼‰

        æ±ºç­–å“è³ªå®šç¾©ï¼š
        - å¥½çš„é€²å ´æ±ºç­–ï¼šè²·å…¥å¾Œæœ€çµ‚ç²åˆ©
        - å¥½çš„å‡ºå ´æ±ºç­–ï¼šè³£å‡ºæ™‚ pnl > 0 æˆ–åœæåŸ·è¡Œå¾—ç•¶
        """
        try:
            adapter = self._portfolio_provider

            if not adapter.connect():
                return self._default_decision_quality("âš ï¸ ç„¡æ³•é€£ç·š")

            # å–å¾—ä»Šå¹´äº¤æ˜“ç´€éŒ„
            today = datetime.now()
            year_start = datetime(today.year, 1, 1)
            trades = adapter.get_profit_loss_history(
                begin_date=year_start.strftime("%Y-%m-%d"),
                end_date=today.strftime("%Y-%m-%d"),
            )
            adapter.disconnect()

            if not trades:
                return self._default_decision_quality("ä»Šå¹´å°šç„¡å·²çµç®—äº¤æ˜“")

            # åˆ†æé€²å ´æ±ºç­–ï¼ˆè²·å…¥å¾Œæœ€çµ‚æ˜¯å¦ç²åˆ©ï¼‰
            good_entries = sum(1 for t in trades if t.get("pnl", 0) > 0)
            total_entries = len(trades)

            # åˆ†æå‡ºå ´æ±ºç­–
            # å¥½çš„å‡ºå ´ï¼šç²åˆ©å‡ºå ´ æˆ– æ§åˆ¶è™§æåœ¨åˆç†ç¯„åœ (< 10%)
            good_exits = sum(
                1
                for t in trades
                if t.get("pnl", 0) > 0 or t.get("pnl_percent", 0) > -10
            )
            total_exits = len(trades)

            # è¨ˆç®—ç¸½é«”å¥½æ±ºç­–ç‡ (åŠ æ¬Šå¹³å‡)
            total_good = good_entries + good_exits
            total_decisions = total_entries + total_exits
            good_rate = total_good / total_decisions if total_decisions > 0 else 0

            return {
                "good_decision_rate": round(good_rate, 4),
                "entries": {"good": good_entries, "total": total_entries},
                "exits": {"good": good_exits, "total": total_exits},
                "note": f"âœ… åŸºæ–¼ {len(trades)} ç­†äº¤æ˜“åˆ†æ",
            }
        except Exception as e:
            self._logger.warning(f"æ±ºç­–å“è³ªè¨ˆç®—å¤±æ•—: {e}")
            return self._default_decision_quality(f"âš ï¸ è¨ˆç®—å¤±æ•—: {e}")

    def _default_decision_quality(self, note: str) -> DecisionQualityDTO:
        """é è¨­æ±ºç­–å“è³ªï¼ˆè³‡æ–™ä¸è¶³æ™‚ï¼‰"""
        return {
            "good_decision_rate": 0.0,
            "entries": {"good": 0, "total": 0},
            "exits": {"good": 0, "total": 0},
            "note": note,
        }

    def _get_thesis_validation(self) -> ThesisValidationDTO:
        """å–å¾—è«–é»é©—è­‰ (å·²åœç”¨ï¼Œå›å‚³ç©ºçµæ§‹)"""
        return {
            "total_theses": 0,
            "valid_theses": 0,
            "validity_rate": 0.0,
            "details": [],
        }

    def _get_strategy_health(self) -> StrategyHealthDTO:
        """å–å¾—ç­–ç•¥å¥åº·åº¦ (DSR/CVaR/CPCV) â€” ä½¿ç”¨çœŸå¯¦äº¤æ˜“è³‡æ–™

        æ•´åˆï¼š
        - DSR (Deflated Sharpe Ratio): èª¿æ•´å¤šé‡æ¸¬è©¦åå·®çš„å¤æ™®æ¯”ç‡
        - CVaR (Conditional VaR): å°¾éƒ¨é¢¨éšªè©•ä¼°
        - WFO (Walk-Forward Optimization): æ¨£æœ¬å¤–å¤æ™®
        - CPCV (Combinatorial Purged CV): å¤æ™®åˆ†å¸ƒ
        - PBO (Probability of Backtest Overfitting): éæ“¬åˆæ¦‚ç‡
        """
        try:
            from libs.reviewing.src.domain.services.wfo_validator import (
                walk_forward_optimization,
                probability_backtest_overfitting,
            )
            from libs.reviewing.src.domain.services.cpcv_validator import (
                cpcv_validate,
            )

            adapter = self._portfolio_provider

            if not adapter.connect():
                return self._default_strategy_health("âš ï¸ ç„¡æ³•é€£ç·š Shioaji")

            # å–å¾—éå»ä¸€å¹´çš„äº¤æ˜“ç´€éŒ„
            today = datetime.now()
            year_ago = today - timedelta(days=365)
            trades = adapter.get_profit_loss_history(
                begin_date=year_ago.strftime("%Y-%m-%d"),
                end_date=today.strftime("%Y-%m-%d"),
            )
            adapter.disconnect()

            if len(trades) < 10:
                return self._default_strategy_health(
                    f"éœ€ç´¯ç©è‡³å°‘ 10 ç­†äº¤æ˜“ (ç›®å‰ {len(trades)} ç­†)"
                )

            # è¨ˆç®—æ¯ç­†äº¤æ˜“å ±é…¬ç‡
            returns = [
                t.get("pnl", 0) / t.get("cost", 1)
                for t in trades
                if t.get("cost", 0) > 0
            ]

            if not returns:
                return self._default_strategy_health("âš ï¸ ç„¡æœ‰æ•ˆäº¤æ˜“è³‡æ–™")

            # è¨ˆç®—å¤æ™®æ¯”ç‡ (å¹´åŒ–ï¼Œå‡è¨­æ¯æœˆç´„ 10 ç­†äº¤æ˜“)
            mean_ret = np.mean(returns)
            std_ret = np.std(returns)
            sharpe_ratio = (mean_ret / std_ret) * np.sqrt(120) if std_ret > 0 else 0

            # è¨ˆç®— DSR (Deflated Sharpe Ratio)
            dsr = calculate_deflated_sharpe_ratio(
                sr=sharpe_ratio,
                n_trials=5,  # å‡è¨­æ¸¬è©¦é 5 å€‹ç­–ç•¥è®Šé«”
                n_observations=len(returns),
                sr_std=1.0,
            )

            # è¨ˆç®— CVaR
            cvar_result = assess_tail_risk(returns, confidence_level=0.95)

            # è©•ä¼°ç­–ç•¥å¥åº·ç‹€æ…‹ (methodology.md DSR åˆ¤æº–)
            if dsr >= 0.95:
                dsr_status = "âœ… æœ‰æ•ˆç­–ç•¥"
                dsr_verdict = "ç­–ç•¥æœ‰æ•ˆæ€§é«˜"
            elif dsr >= 0.80:
                dsr_status = "ğŸŸ¡ ç°è‰²åœ°å¸¶"
                dsr_verdict = "éœ€é€²ä¸€æ­¥é©—è­‰"
            else:
                dsr_status = "âš ï¸ å½é™½æ€§é¢¨éšª"
                dsr_verdict = "è€ƒæ…®æ£„ç”¨æ­¤ç­–ç•¥"

            # è©•ä¼°å°¾éƒ¨é¢¨éšª
            tail_ratio = cvar_result.get("tail_ratio", 1.0)
            if tail_ratio > 1.5:
                tail_risk = "âš ï¸ è‚¥å°¾ (é«˜é¢¨éšª)"
            elif tail_ratio > 1.2:
                tail_risk = "ğŸŸ¡ ç•¥é«˜"
            else:
                tail_risk = "ğŸŸ¢ æ­£å¸¸"

            # ===== WFO: è¨ˆç®—çœŸå¯¦ OOS å¤æ™® =====
            returns_array = np.array(returns)
            equity_curve, is_monotonic = walk_forward_optimization(
                returns_array,
                in_sample_pct=0.7,
                n_splits=5,
            )

            if len(equity_curve) > 1:
                # ä½¿ç”¨ OOS æ¬Šç›Šæ›²ç·šè¨ˆç®—å¤æ™®
                oos_returns = np.diff(equity_curve) / (np.abs(equity_curve[:-1]) + 1e-8)
                oos_mean = np.mean(oos_returns)
                oos_std = np.std(oos_returns)
                oos_sharpe = (oos_mean / oos_std) * np.sqrt(120) if oos_std > 0 else 0
            else:
                oos_sharpe = 0

            # ===== CPCV: è¨ˆç®—çœŸå¯¦å¤æ™®åˆ†å¸ƒ =====
            cpcv_result = cpcv_validate(returns, n_splits=5)
            cpcv_mean = cpcv_result["mean_sharpe"]

            # ===== PBO: è¨ˆç®—éæ“¬åˆæ¦‚ç‡ =====
            # éœ€è¦ IS/OOS å¤æ™®å°ï¼Œä½¿ç”¨ WFO åˆ†å‰²ä¾†ä¼°ç®—
            n_splits = 5
            if len(returns_array) >= n_splits * 2:
                split_size = len(returns_array) // n_splits
                is_sharpes = []
                oos_sharpes = []

                for i in range(n_splits):
                    start = i * split_size
                    end = start + split_size
                    is_end = int(start + split_size * 0.7)

                    is_data = returns_array[start:is_end]
                    oos_data = returns_array[is_end:end]

                    if len(is_data) > 1 and len(oos_data) > 1:
                        is_sr = (
                            (np.mean(is_data) / np.std(is_data)) * np.sqrt(120)
                            if np.std(is_data) > 0
                            else 0
                        )
                        oos_sr = (
                            (np.mean(oos_data) / np.std(oos_data)) * np.sqrt(120)
                            if np.std(oos_data) > 0
                            else 0
                        )
                        is_sharpes.append(is_sr)
                        oos_sharpes.append(oos_sr)

                if is_sharpes and oos_sharpes:
                    pbo = (
                        probability_backtest_overfitting(
                            np.array(is_sharpes),
                            np.array(oos_sharpes),
                        )
                        * 100
                    )  # è½‰æ›ç‚ºç™¾åˆ†æ¯”

                    # ===== FDR: ä½¿ç”¨ B-H æ–¹æ³•æ§åˆ¶å¤šé‡æ¸¬è©¦å‡é™½æ€§ =====
                    # è¨ˆç®—æ¯å€‹ split çš„ p-value (é›™å´ z-test è¿‘ä¼¼)
                    from scipy import stats

                    pvalues = []
                    for is_sr, oos_sr in zip(is_sharpes, oos_sharpes):
                        # p-value = P(|SR| > observed | H0: SR = 0)
                        z = oos_sr / (1.0 / np.sqrt(split_size) + 1e-8)
                        p = 2 * (1 - stats.norm.cdf(abs(z)))
                        pvalues.append(p)
                    fdr_result = control_fdr(pvalues, alpha=0.05)
                    fdr_discoveries = fdr_result["n_discoveries"]
                    fdr_tested = fdr_result["n_tested"]
                else:
                    pbo = 50.0
                    fdr_discoveries = 0
                    fdr_tested = 0
            else:
                pbo = 50.0
                fdr_discoveries = 0
                fdr_tested = 0

            return {
                "dsr": round(dsr, 2),
                "dsr_status": dsr_status,
                "dsr_verdict": dsr_verdict,
                "sharpe_ratio": round(sharpe_ratio, 2),
                "cvar_95": round(cvar_result.get("cvar", -0.02) * 100, 2),
                "var_95": round(cvar_result.get("var", -0.015) * 100, 2),
                "tail_risk": tail_risk,
                "oos_sharpe": round(oos_sharpe, 2),
                "wfo_monotonic": is_monotonic,
                "pbo": round(pbo, 1),
                "cpcv_mean": round(cpcv_mean, 2),
                "cpcv_valid": cpcv_result["is_valid"],
                "fdr_discoveries": fdr_discoveries,
                "fdr_tested": fdr_tested,
                "note": f"âœ… è³‡æ–™ä¾†æº: {len(trades)} ç­†äº¤æ˜“",
            }
        except Exception as e:
            self._logger.warning(f"ç­–ç•¥å¥åº·åº¦è¨ˆç®—å¤±æ•—: {e}")
            return self._default_strategy_health(f"âš ï¸ è¨ˆç®—å¤±æ•—: {e}")

    def _default_strategy_health(self, note: str = "è³‡æ–™ä¸è¶³") -> StrategyHealthDTO:
        """é è¨­ç­–ç•¥å¥åº·åº¦ (è³‡æ–™ä¸è¶³æ™‚)"""
        return {
            "dsr": 0.0,
            "dsr_status": "N/A",
            "dsr_verdict": note,
            "sharpe_ratio": 0.0,
            "cvar_95": 0.0,
            "var_95": 0.0,
            "tail_risk": "N/A",
            "oos_sharpe": 0.0,
            "wfo_monotonic": False,
            "pbo": 0.0,
            "cpcv_mean": 0.0,
            "cpcv_valid": False,
            "fdr_discoveries": 0,
            "fdr_tested": 0,
            "note": note,
        }

    def _generate_narrative(self, _performance: dict, _skill: dict) -> str:
        """ç”Ÿæˆ AI æ•˜äº‹ (æš«æ™‚åœç”¨ LLMï¼Œå¾… Gemini Adapter é·ç§»è‡³ libs/ å¾Œå•Ÿç”¨)"""
        # TODO: å¾…å»ºç«‹ libs/shared/src/adapters/driven/gemini/ å¾Œé‡æ–°å•Ÿç”¨
        return ""

    def _generate_report(
        self,
        period: str,
        performance: dict,
        skill: dict,
        crowding: dict,
        decision_quality: dict,
        thesis_validation: dict,
        strategy_health: dict,
    ) -> str:
        """ç”Ÿæˆ Markdown å ±å‘Š (å«åˆ¤æº–å®šç¾©ï¼Œä¾› LLM è§£è®€)"""

        # ç¸¾æ•ˆè©•èª
        mtd_comment = (
            "è¡¨ç¾å„ªç•°"
            if performance["mtd_return"] > 0.02
            else "ç¬¦åˆé æœŸ"
            if performance["mtd_return"] > 0
            else "å¾…æ”¹é€²"
        )
        sharpe_comment = (
            "å„ªç§€"
            if performance["sharpe_ratio"] > 1.5
            else "è‰¯å¥½"
            if performance["sharpe_ratio"] > 1
            else "æ™®é€š"
        )

        report = (
            dedent(f"""
            # ğŸ“ˆ é€±åº¦è¦†ç›¤ â€” {period}

            > ç”Ÿæˆæ™‚é–“ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M")}

            ---

            ## ğŸ“Š ç¸¾æ•ˆç¸½è¦½

            | æŒ‡æ¨™ | æ•¸å€¼ | èªªæ˜ |
            |------|------|------|
            | é€±å ±é…¬ (WTD) | {performance["mtd_return"]:.1%} | {mtd_comment}ï¼Œæœ¬é€±æŠ•è³‡çµ„åˆç¸½å ±é…¬ |
            | å¹´å ±é…¬ (YTD) | {performance["ytd_return"]:.1%} | ä»Šå¹´ç´¯è¨ˆå ±é…¬ |
            | å¤æ™®æ¯”ç‡ | {performance["sharpe_ratio"]:.2f} | {sharpe_comment}ï¼Œ>1 ç‚ºä½³ï¼Œé¢¨éšªèª¿æ•´å¾Œå ±é…¬ |
            | æœ€å¤§å›æ’¤ | {performance["max_drawdown"]:.1%} | æœŸé–“æœ€å¤§è·Œå¹…ï¼Œæ„ˆå°æ„ˆå¥½ |
            | å‹ç‡ | {performance["win_rate"]:.0%} | ç²åˆ©äº¤æ˜“çš„æ¯”ä¾‹ |
            | ç›ˆè™§æ¯” | {performance["profit_factor"]:.1f} | å¹³å‡ç²åˆ©/å¹³å‡è™§æï¼Œ>1.5 ç‚ºä½³ |
        """).strip()
            + "\n\n"
        )

        report += dedent("""
> ### ğŸ“Š åˆ¤æº–å®šç¾© (Performance Metrics)
>
> | æŒ‡æ¨™ | å„ªç§€ | è‰¯å¥½ | å¾…æ”¹é€² |
> |------|------|------|--------|
> | é€±å ±é…¬ | > 2% | 0~2% | < 0% |
> | å¤æ™®æ¯”ç‡ | > 1.5 | 1.0~1.5 | < 1.0 |
> | æœ€å¤§å›æ’¤ | < 5% | 5~10% | > 10% |
> | å‹ç‡ | > 60% | 50~60% | < 50% |
> | ç›ˆè™§æ¯” | > 2.0 | 1.5~2.0 | < 1.5 |

---
        """)

        report += (
            dedent(f"""
            ## ğŸ¯ æŠ€èƒ½åˆ¤å®š

            | æŒ‡æ¨™ | æ•¸å€¼ | è§£è®€ | èªªæ˜ |
            |------|------|------|------|
            | DSR (èª¿æ•´å¾Œå¤æ™®) | {skill["dsr"]:.2f} | {"å„ªç§€" if skill["dsr"] > 0.5 else "æ™®é€š"} | æ‰£é™¤é‹æ°£æˆåˆ†çš„å¤æ™®ï¼Œ>0.5 æœ‰æŠ€èƒ½ |
            | PSR (æ©Ÿç‡å¤æ™®) | {skill["psr"]:.1f}% | {"æœ‰ä¿¡å¿ƒ" if skill["psr"] > 80 else "å¾…è§€å¯Ÿ"} | çœŸå¯¦å¤æ™®>0 çš„æ©Ÿç‡ï¼Œ>95% å¯ç¢ºèª |
            | **åˆ¤å®š** | **{skill["verdict"]}** | ä¿¡å¿ƒåº¦: {skill["confidence"]} | ç¸¾æ•ˆä¾†è‡ªæŠ€èƒ½é‚„æ˜¯é‹æ°£ï¼Ÿ |

            > ğŸ’¡ **æŠ€èƒ½ vs é‹æ°£**ï¼š
            > - **æŠ€èƒ½ä¸»å°**ï¼šå¯æ”¾å¿ƒç¹¼çºŒåŸ·è¡Œç­–ç•¥
            > - **å¯èƒ½æœ‰æŠ€èƒ½**ï¼šç¹¼çºŒè§€å¯Ÿï¼Œé¿å…éåº¦è‡ªä¿¡
            > - **é‹æ°£ä¸»å°**ï¼šè¬¹æ…è©•ä¼°æ˜¯å¦éœ€èª¿æ•´ç­–ç•¥
        """).strip()
            + "\n\n"
        )

        report += dedent("""
> ### ğŸ¯ åˆ¤æº–å®šç¾© (Skill Verdict)
>
> | æŒ‡æ¨™ | è¨ˆç®—æ–¹å¼ | é–€æª» |
> |------|----------|------|
> | DSR (Deflated Sharpe Ratio) | èª¿æ•´é‹æ°£èˆ‡å¤šé‡æ¸¬è©¦ | > 0.5 = æŠ€èƒ½ |
> | PSR (Probabilistic Sharpe Ratio) | çœŸå¯¦ SR > 0 çš„æ©Ÿç‡ | > 95% = ç¢ºèª |
>
> | DSR | PSR | åˆ¤å®š | ä¿¡å¿ƒ |
> |-----|-----|------|------|
> | > 0.5 | > 95% | æŠ€èƒ½ä¸»å° | é«˜ |
> | 0.3~0.5 | 70~95% | å¯èƒ½æœ‰æŠ€èƒ½ | ä¸­ |
> | < 0.3 | < 70% | é‹æ°£ä¸»å° | ä½ |

---
        """)

        report += (
            dedent(f"""
            ## ğŸ“ˆ ç­–ç•¥æ“æ“ åº¦

            | æŒ‡æ¨™ | æ•¸å€¼ | ç‹€æ…‹ | èªªæ˜ |
            |------|------|------|------|
            | æˆå°ç›¸é—œæ€§ | {crowding["pairwise_correlation"]:.2f} | {"æ­£å¸¸" if crowding["pairwise_correlation"] < 0.7 else "åé«˜"} | æŒå€‰é–“çš„ç›¸é—œæ€§ï¼Œ<0.5 åˆ†æ•£è‰¯å¥½ |
            | å¹³å€‰å¤©æ•¸ | {crowding["days_to_cover"]:.1f} | {"å®‰å…¨" if crowding["days_to_cover"] < 5 else "åé•·"} | è‹¥éœ€å‡ºå ´ï¼Œéœ€å¹¾å¤©æ‰èƒ½è³£å®Œ |
            | Alpha åŠè¡°æœŸ | {crowding["alpha_half_life"]:.1f} é€± | {crowding["status"]} | è¶…é¡å ±é…¬æ¶ˆå¤±ä¸€åŠçš„æ™‚é–“ |

            **å»ºè­°**ï¼š{crowding["recommendation"]}

            > ğŸ’¡ æ“æ“ åº¦é«˜ = å¾ˆå¤šäººç”¨é¡ä¼¼ç­–ç•¥ï¼ŒAlpha å¯èƒ½åŠ é€Ÿæ¶ˆå¤±
        """).strip()
            + "\n\n"
        )

        report += dedent("""
> ### ğŸ”— åˆ¤æº–å®šç¾© (Crowding)
>
> | æŒ‡æ¨™ | æ­£å¸¸ | è­¦æˆ’ | å±éšª | èªªæ˜ |
> |------|------|------|------|------|
> | æˆå°ç›¸é—œæ€§ | < 0.5 | 0.5~0.7 | > 0.7 | æŒå€‰é–“ç›¸é—œåº¦ |
> | å¹³å€‰å¤©æ•¸ | < 3 | 3~5 | > 5 | è‹¥éœ€å‡ºå ´å¤šä¹…èƒ½è³£å®Œ |
> | Alpha åŠè¡°æœŸ | > 12é€± | 8~12é€± | < 8é€± | è¶…é¡å ±é…¬æ¶ˆå¤±é€Ÿåº¦ |

---
        """)

        report += (
            dedent(f"""
            ## âœ… æ±ºç­–å“è³ªå¯©è¨ˆ

            | æŒ‡æ¨™ | æ•¸å€¼ | èªªæ˜ |
            |------|------|------|
            | å¥½æ±ºç­–ç‡ | {decision_quality["good_decision_rate"]:.0%} | æ­£ç¢ºæ±ºç­–çš„æ¯”ä¾‹ï¼Œ>60% ç‚ºä½³ |
            | é€²å ´æ±ºç­– | {decision_quality["entries"]["good"]}/{decision_quality["entries"]["total"]} æ­£ç¢º | è²·å…¥æ™‚æ©Ÿæ˜¯å¦æ­£ç¢º |
            | å‡ºå ´æ±ºç­– | {decision_quality["exits"]["good"]}/{decision_quality["exits"]["total"]} æ­£ç¢º | è³£å‡ºæ™‚æ©Ÿæ˜¯å¦æ­£ç¢º |

            > ğŸ’¡ å¥½æ±ºç­–ä¸ä¸€å®šè³ºéŒ¢ï¼Œä½†é•·æœŸä¾†çœ‹å¥½æ±ºç­–æœƒå¸¶ä¾†å¥½çµæœ
        """).strip()
            + "\n\n"
        )

        report += dedent("""
> ### âœ… åˆ¤æº–å®šç¾© (Decision Quality)
>
> | å¥½æ±ºç­–ç‡ | è©•åƒ¹ | å»ºè­° |
> |----------|------|------|
> | > 70% | å„ªç§€ | ç¹¼çºŒä¿æŒç¾æœ‰ç´€å¾‹ |
> | 50~70% | æ™®é€š | æª¢è¦–é€²å‡ºå ´è¦å‰‡ |
> | < 50% | å¾…åŠ å¼· | éœ€èª¿æ•´ç­–ç•¥æˆ–å¿ƒæ…‹ |

---
        """)

        report += (
            dedent(f"""
            ## ğŸ“Š ç­–ç•¥å¥åº·åº¦

            | æŒ‡æ¨™ | æ•¸å€¼ | åˆ¤æº– | ç‹€æ…‹ |
            |------|------|------|------|
            | Deflated Sharpe (DSR) | {strategy_health["dsr"]:.2f} | > 0.95 | {strategy_health["dsr_status"]} |
            | æ¨£æœ¬å¤–å¤æ™® (OOS) | {strategy_health["oos_sharpe"]:.2f} | > 1.0 | {"âœ…" if strategy_health["oos_sharpe"] > 1.0 else "âš ï¸"} |
            | éæ“¬åˆæ©Ÿç‡ (PBO) | {strategy_health["pbo"]:.0f}% | < 30% | {"âœ…" if strategy_health["pbo"] < 30 else "âš ï¸"} |
            | CPCV å¤æ™®åˆ†å¸ƒ Î¼ | {strategy_health["cpcv_mean"]:.2f} | > 1.0 | {"âœ…" if strategy_health["cpcv_mean"] > 1.0 else "âš ï¸"} |
            | FDR é€šé | {strategy_health["fdr_discoveries"]}/{strategy_health["fdr_tested"]} | B-H Î±=0.05 | {"âœ…" if strategy_health["fdr_discoveries"] > 0 else "âš ï¸"} |
            | CVaR 95% | {strategy_health["cvar_95"]:.2f}% | - | {strategy_health["tail_risk"]} |

            **åˆ¤å®š**ï¼š{strategy_health["dsr_verdict"]}

            > ğŸ’¡ **ç­–ç•¥å¥åº·åº¦**ï¼šè¾¨åˆ¥ç¸¾æ•ˆä¾†è‡ªæŠ€èƒ½é‚„æ˜¯é‹æ°£ï¼Œé è­¦ Alpha è¡°æ¸›é¢¨éšª
        """).strip()
            + "\n\n"
        )

        report += dedent("""
> ### ğŸ“Š åˆ¤æº–å®šç¾© (Strategy Health)
>
> | æŒ‡æ¨™ | è¨ˆç®—æ–¹å¼ | é€šéæ¢ä»¶ |
> |------|----------|----------|
> | DSR (Deflated Sharpe) | èª¿æ•´å¤šé‡æ¸¬è©¦åå·® | > 0.95 |
> | OOS Sharpe | æ¨£æœ¬å¤–å¤æ™®æ¯”ç‡ | > 1.0 |
> | PBO | éæ“¬åˆæ©Ÿç‡ | < 30% |
> | CPCV Î¼ | äº¤å‰é©—è­‰å¤æ™®å¹³å‡ | > 1.0 |
> | FDR | Benjamini-Hochberg æ§åˆ¶ | è‡³å°‘ 1 ç­–ç•¥é€šé |

---
        """)

        report += dedent("""
            ## ğŸ“‹ è«–é»é©—è­‰

            | æ¨™çš„ | è«–é» | æœ‰æ•ˆ | èªªæ˜ |
            |------|------|------|------|
            """)
        for thesis in thesis_validation["details"]:
            valid_icon = "âœ…" if thesis["valid"] else "âŒ"
            desc = "è«–é»æ­£ç¢ºï¼ŒæŒçºŒæŒæœ‰" if thesis["valid"] else "è«–é»å¤±æ•ˆï¼Œè€ƒæ…®å‡ºå ´"
            report += (
                f"| {thesis['symbol']} | {thesis['thesis']} | {valid_icon} | {desc} |\n"
            )

        report += (
            dedent(f"""
            **æœ‰æ•ˆç‡**ï¼š{thesis_validation["valid_theses"]}/{thesis_validation["total_theses"]} ({thesis_validation["validity_rate"]:.0%})

            > ğŸ’¡ è«–é»é©—è­‰ï¼šç¢ºèªç•¶åˆè²·å…¥çš„ç†ç”±æ˜¯å¦ä»ç„¶æˆç«‹

            ---
        """).strip()
            + "\n\n"
        )

        report += dedent("""
> ### ğŸ“‹ åˆ¤æº–å®šç¾© (Thesis Validation)
>
> | æœ‰æ•ˆç‡ | è©•ä¼° | å»ºè­° |
> |--------|------|------|
> | > 75% | è‰¯å¥½ | è«–é»å“è³ªé«˜ |
> | 50~75% | æ™®é€š | æª¢è¦–å¤±æ•ˆè«–é» |
> | < 50% | åä½ | é‡æ–°å¯©è¦–æŠ•è³‡æ¡†æ¶ |

---

_æœ¬å ±å‘Šç”± `report_generator` ç”Ÿæˆï¼Œè¨­è¨ˆä¾› LLM è§£è®€ä½¿ç”¨_
        """)

        return report

    def _send_email(self, report: str, period: str) -> bool:
        """ç™¼é€ Email (Markdown â†’ HTML)"""
        try:
            adapter = self._notification_gateway
            return adapter.send_markdown_email(
                subject=f"ğŸ“Š MyFin é€±åº¦è¦†ç›¤ - {period}",
                markdown_content=report,
            )
        except Exception:
            return False
